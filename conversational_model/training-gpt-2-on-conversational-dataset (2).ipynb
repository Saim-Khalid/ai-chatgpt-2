{"cells":[{"cell_type":"markdown","metadata":{},"source":["## BIOGPT\n","- Use biogpt pretrain model\n","- fine tune biogpt on medical dataset using distributed training.\n"," "]},{"cell_type":"markdown","metadata":{},"source":["# Import Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T10:47:30.418141Z","iopub.status.busy":"2023-07-19T10:47:30.417668Z","iopub.status.idle":"2023-07-19T10:48:21.387019Z","shell.execute_reply":"2023-07-19T10:48:21.385921Z","shell.execute_reply.started":"2023-07-19T10:47:30.418099Z"},"trusted":true},"outputs":[],"source":["!pip install transformers==4.27.4\n","!pip install sacremoses\n","from transformers import BioGptTokenizer, BioGptForCausalLM, TrainerCallback\n","from transformers import Trainer, TrainingArguments\n","\n","# print(transformers.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import io\n","import requests\n","import numpy as np\n","import pandas as pd\n","import re\n","import zipfile\n","import random\n","import time\n","import csv\n","import datetime\n","from itertools import compress\n","from collections import Counter, defaultdict\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","from transformers import AutoTokenizer, AutoConfig, AutoModelForPreTraining, \\\n","                         AdamW, get_linear_schedule_with_warmup, \\\n","                         TrainingArguments, BeamScorer, Trainer\n","\n","import torch\n","from torch.utils.data import Dataset, random_split, DataLoader, \\\n","                             RandomSampler, SequentialSampler\n","\n","from IPython.display import clear_output\n","\n","print(f\"PyTorch version: {torch.__version__}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T10:48:35.651960Z","iopub.status.busy":"2023-07-19T10:48:35.651207Z","iopub.status.idle":"2023-07-19T10:48:36.729982Z","shell.execute_reply":"2023-07-19T10:48:36.728480Z","shell.execute_reply.started":"2023-07-19T10:48:35.651917Z"},"trusted":true},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"lZDy9RClRiQ3"},"source":["### Configurations"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T10:48:39.801191Z","iopub.status.busy":"2023-07-19T10:48:39.799338Z","iopub.status.idle":"2023-07-19T10:48:39.810547Z","shell.execute_reply":"2023-07-19T10:48:39.809421Z","shell.execute_reply.started":"2023-07-19T10:48:39.801137Z"},"id":"QILzrXuoRhaF","trusted":true},"outputs":[],"source":["DEBUG           = False\n","\n","INPUT_DIR       = 'articles'\n","\n","USE_APEX        = True\n","APEX_OPT_LEVEL  = 'O1'\n","\n","MODEL           = 'microsoft/biogpt' #{gpt2, gpt2-medium, gpt2-large, gpt2-xl}\n","\n","UNFREEZE_LAST_N = 6 #The last N layers to unfreeze for training\n","\n","SPECIAL_TOKENS  = { \"bos_token\": \"<|BOS|>\",\n","                    \"eos_token\": \"<|EOS|>\",\n","                    \"unk_token\": \"<|UNK|>\",                    \n","                    \"pad_token\": \"<|PAD|>\",\n","                    \"sep_token\": \"<|SEP|>\"}\n","                    \n","MAXLEN          = 256  #{768, 1024, 1280, 1600}\n","\n","TRAIN_SIZE      = 0.8\n","\n","if USE_APEX:\n","    TRAIN_BATCHSIZE = 8\n","    BATCH_UPDATE    = 2\n","else:\n","    TRAIN_BATCHSIZE = 2\n","    BATCH_UPDATE    = 4\n","\n","EPOCHS          = 3\n","LR              = 5e-4\n","EPS             = 1e-8\n","WARMUP_STEPS    = 1e2\n","\n","SEED            = 2020\n","\n","\n","DEVIDE_BY = 5\n","\n","os.environ['WANDB_DISABLED'] = 'true'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T10:48:42.255094Z","iopub.status.busy":"2023-07-19T10:48:42.254658Z","iopub.status.idle":"2023-07-19T10:48:42.265005Z","shell.execute_reply":"2023-07-19T10:48:42.263947Z","shell.execute_reply.started":"2023-07-19T10:48:42.255058Z"},"id":"740ZIyZXRbWe","trusted":true},"outputs":[],"source":["def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","\n","seed_everything(SEED)"]},{"cell_type":"markdown","metadata":{"id":"5RpxktDOHpMI"},"source":["### Using medical dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T10:48:43.942423Z","iopub.status.busy":"2023-07-19T10:48:43.942033Z","iopub.status.idle":"2023-07-19T10:48:48.773866Z","shell.execute_reply":"2023-07-19T10:48:48.772660Z","shell.execute_reply.started":"2023-07-19T10:48:43.942384Z"},"trusted":true},"outputs":[],"source":["train_df = pd.read_csv('/kaggle/input/conversational-desc/train.csv')\n","test_df = pd.read_csv('/kaggle/input/conversational-desc/test.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T10:48:48.776565Z","iopub.status.busy":"2023-07-19T10:48:48.776157Z","iopub.status.idle":"2023-07-19T10:48:48.907001Z","shell.execute_reply":"2023-07-19T10:48:48.905913Z","shell.execute_reply.started":"2023-07-19T10:48:48.776526Z"},"trusted":true},"outputs":[],"source":["train_df = train_df.dropna()\n","train_df = train_df.astype('str')\n","test_df = test_df.dropna()\n","test_df = test_df.astype('str')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T10:48:48.909571Z","iopub.status.busy":"2023-07-19T10:48:48.908741Z","iopub.status.idle":"2023-07-19T10:48:48.931638Z","shell.execute_reply":"2023-07-19T10:48:48.929800Z","shell.execute_reply.started":"2023-07-19T10:48:48.909528Z"},"trusted":true},"outputs":[],"source":["train_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T10:48:51.810917Z","iopub.status.busy":"2023-07-19T10:48:51.810486Z","iopub.status.idle":"2023-07-19T10:48:51.891653Z","shell.execute_reply":"2023-07-19T10:48:51.890547Z","shell.execute_reply.started":"2023-07-19T10:48:51.810870Z"},"trusted":true},"outputs":[],"source":["train_df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T10:48:53.699759Z","iopub.status.busy":"2023-07-19T10:48:53.698990Z","iopub.status.idle":"2023-07-19T10:48:53.715654Z","shell.execute_reply":"2023-07-19T10:48:53.714591Z","shell.execute_reply.started":"2023-07-19T10:48:53.699721Z"},"trusted":true},"outputs":[],"source":["sum = 0\n","sample_num = 500\n","for review in train_df.sample(sample_num).iloc[:, 1]:  # 0 for the translated recipe name 1 for translatedinstructions\n","    sum += len(review.split(' '))\n","print(sum/sample_num)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T10:48:56.380651Z","iopub.status.busy":"2023-07-19T10:48:56.379784Z","iopub.status.idle":"2023-07-19T10:48:56.403843Z","shell.execute_reply":"2023-07-19T10:48:56.402896Z","shell.execute_reply.started":"2023-07-19T10:48:56.380615Z"},"trusted":true},"outputs":[],"source":["# For debug\n","train_df = train_df.sample(10000)\n","test_df = test_df.sample(int(len(test_df) / DEVIDE_BY / 5))\n","f'There are {len(train_df) :,} samples for training, and {len(test_df) :,} samples for validation testing'"]},{"cell_type":"markdown","metadata":{"id":"2j0V83HbH6QF"},"source":["### Datasets and loaders"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T10:48:58.895130Z","iopub.status.busy":"2023-07-19T10:48:58.894017Z","iopub.status.idle":"2023-07-19T10:48:58.906168Z","shell.execute_reply":"2023-07-19T10:48:58.904921Z","shell.execute_reply.started":"2023-07-19T10:48:58.895080Z"},"id":"I8gp0I8JnMEE","trusted":true},"outputs":[],"source":["class myDataset(Dataset):\n","\n","    def __init__(self, data, tokenizer, randomize=True):\n","        self.randomize = randomize\n","        self.tokenizer = tokenizer \n","        self.title     = data.iloc[:, 0].tolist()\n","        self.text      = data.iloc[:, 1].tolist()\n","\n","\n","    #---------------------------------------------#\n","\n","    def __len__(self):\n","        return len(self.text)\n","\n","    #---------------------------------------------#\n","    \n","    def __getitem__(self, i):\n","        input = SPECIAL_TOKENS['bos_token'] + self.title[i] + SPECIAL_TOKENS['sep_token'] + self.text[i] + SPECIAL_TOKENS['eos_token']\n","\n","        encodings_dict = tokenizer(input,                                   \n","                                   truncation=True, \n","                                   max_length=MAXLEN, \n","                                   padding=\"max_length\")   \n","        \n","        input_ids = encodings_dict['input_ids']\n","        attention_mask = encodings_dict['attention_mask']\n","        \n","        return {'label': torch.tensor(input_ids),\n","                'input_ids': torch.tensor(input_ids), \n","                'attention_mask': torch.tensor(attention_mask)}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T10:49:00.263575Z","iopub.status.busy":"2023-07-19T10:49:00.263155Z","iopub.status.idle":"2023-07-19T10:49:00.269990Z","shell.execute_reply":"2023-07-19T10:49:00.268271Z","shell.execute_reply.started":"2023-07-19T10:49:00.263539Z"},"trusted":true},"outputs":[],"source":["def split_data(data, S=TRAIN_SIZE):\n","    train_data = data.sample(frac = TRAIN_SIZE)\n","    val_data = data.drop(train_data.index)\n","\n","    return train_data, val_data"]},{"cell_type":"markdown","metadata":{"id":"v3LfEbc5j9Yo"},"source":["### Loading Tokenizer, Config and Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T10:49:02.353272Z","iopub.status.busy":"2023-07-19T10:49:02.351952Z","iopub.status.idle":"2023-07-19T10:49:02.365009Z","shell.execute_reply":"2023-07-19T10:49:02.363927Z","shell.execute_reply.started":"2023-07-19T10:49:02.353230Z"},"id":"knL24TEIX9fl","trusted":true},"outputs":[],"source":["def get_tokenier(special_tokens=None):\n","    tokenizer = AutoTokenizer.from_pretrained(MODEL) #GPT2Tokenizer\n","\n","    if special_tokens:\n","        tokenizer.add_special_tokens(special_tokens)\n","        print(\"Special tokens added\")\n","    return tokenizer\n","\n","def get_model(tokenizer, special_tokens=None, load_model_path=None):\n","\n","    #GPT2LMHeadModel\n","    if special_tokens:\n","        config = AutoConfig.from_pretrained(MODEL, \n","                                            bos_token_id=tokenizer.bos_token_id,\n","                                            eos_token_id=tokenizer.eos_token_id,\n","                                            sep_token_id=tokenizer.sep_token_id,\n","                                            pad_token_id=tokenizer.pad_token_id,\n","                                            output_hidden_states=False)\n","    else: \n","        config = AutoConfig.from_pretrained(MODEL,                                     \n","                                            pad_token_id=tokenizer.eos_token_id,\n","                                            output_hidden_states=False)    \n","\n","    #----------------------------------------------------------------#\n","    model = AutoModelForPreTraining.from_pretrained(MODEL, config=config)\n","\n","    if special_tokens:\n","        #Special tokens added, model needs to be resized accordingly\n","        model.resize_token_embeddings(len(tokenizer))\n","\n","    if load_model_path:\n","        model.load_state_dict(torch.load(load_model_path))\n","\n","    model.cuda()\n","    return model"]},{"cell_type":"markdown","metadata":{},"source":["# Load Pretrain model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T10:49:08.390436Z","iopub.status.busy":"2023-07-19T10:49:08.389993Z","iopub.status.idle":"2023-07-19T10:49:24.437222Z","shell.execute_reply":"2023-07-19T10:49:24.436035Z","shell.execute_reply.started":"2023-07-19T10:49:08.390401Z"},"trusted":true},"outputs":[],"source":["tokenizer = BioGptTokenizer.from_pretrained(\"microsoft/biogpt\")\n","model = BioGptForCausalLM.from_pretrained(MODEL)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T10:49:26.584465Z","iopub.status.busy":"2023-07-19T10:49:26.584080Z","iopub.status.idle":"2023-07-19T10:49:26.594512Z","shell.execute_reply":"2023-07-19T10:49:26.593226Z","shell.execute_reply.started":"2023-07-19T10:49:26.584432Z"},"trusted":true},"outputs":[],"source":["train_dataset = myDataset(train_df, tokenizer)\n","val_dataset = myDataset(test_df, tokenizer, randomize=False)\n","f'There are {len(train_dataset) :,} samples for training, and {len(val_dataset) :,} samples for validation testing'"]},{"cell_type":"markdown","metadata":{"id":"LYh9gAM_lAxK"},"source":["### Fine-tune Biogpt using Trainer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T10:49:29.823584Z","iopub.status.busy":"2023-07-19T10:49:29.822825Z","iopub.status.idle":"2023-07-19T11:18:42.125653Z","shell.execute_reply":"2023-07-19T11:18:42.124199Z","shell.execute_reply.started":"2023-07-19T10:49:29.823546Z"},"id":"GsKQJis8jcCh","outputId":"dcdf82cf-ceaf-4c30-89f0-62d07f99dd74","trusted":true},"outputs":[],"source":["%%time\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./\",\n","    num_train_epochs=EPOCHS,\n","    per_device_train_batch_size=TRAIN_BATCHSIZE,\n","    per_device_eval_batch_size=TRAIN_BATCHSIZE,\n","    gradient_accumulation_steps=BATCH_UPDATE,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy = 'epoch',\n","    fp16=True,\n","    fp16_opt_level=APEX_OPT_LEVEL,\n","    warmup_steps=WARMUP_STEPS,    \n","    learning_rate=LR,\n","    adam_epsilon=EPS,\n","    weight_decay=0.01,        \n","    save_total_limit=1,\n","    load_best_model_at_end=True,\n","    report_to = None,\n",")\n","\n","#---------------------------------------------------#\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,    \n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    tokenizer=tokenizer\n",")\n","\n","#---------------------------------------------------#\n","trainer.train()\n","trainer.save_model() "]},{"cell_type":"markdown","metadata":{"id":"0azvVPXCx4eM"},"source":["### Generating text with Fine-tuned Biogpt model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rM39_zQLhiZw","trusted":true},"outputs":[],"source":["# !cp -r '/content/drive/MyDrive/Colab Notebooks/Text Generation/pytorch_model_V2.bin' 'pytorch_model.bin' "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T11:23:03.185571Z","iopub.status.busy":"2023-07-19T11:23:03.185134Z","iopub.status.idle":"2023-07-19T11:23:03.201154Z","shell.execute_reply":"2023-07-19T11:23:03.199856Z","shell.execute_reply.started":"2023-07-19T11:23:03.185533Z"},"trusted":true},"outputs":[],"source":["from transformers import GPT2Tokenizer, GPT2LMHeadModel"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T12:01:48.122448Z","iopub.status.busy":"2023-07-19T12:01:48.121693Z","iopub.status.idle":"2023-07-19T12:01:53.163384Z","shell.execute_reply":"2023-07-19T12:01:53.162238Z","shell.execute_reply.started":"2023-07-19T12:01:48.122410Z"},"id":"dojGngEDRupX","outputId":"beea7b67-8385-40c7-d347-a736fd393949","trusted":true},"outputs":[],"source":["tokenizer = BioGptTokenizer.from_pretrained(\"microsoft/biogpt\")\n","model = BioGptForCausalLM.from_pretrained('/kaggle/working/')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T11:26:33.441019Z","iopub.status.busy":"2023-07-19T11:26:33.440535Z","iopub.status.idle":"2023-07-19T11:26:33.800078Z","shell.execute_reply":"2023-07-19T11:26:33.798974Z","shell.execute_reply.started":"2023-07-19T11:26:33.440979Z"},"id":"WYCC-ugJJy3A","trusted":true},"outputs":[],"source":["title = \"i am 24 year old male recently i have been suffering from knee pain what can be the cause of it?\"\n","prompt = SPECIAL_TOKENS['bos_token'] + title + SPECIAL_TOKENS['sep_token'] \n","         \n","generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n","device = torch.device(\"cuda\")\n","generated = generated.to(device)\n","device = torch.device(\"cuda\")\n","model.cuda()\n","model.eval();"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-19T11:26:34.960569Z","iopub.status.busy":"2023-07-19T11:26:34.960187Z","iopub.status.idle":"2023-07-19T11:26:41.788354Z","shell.execute_reply":"2023-07-19T11:26:41.787215Z","shell.execute_reply.started":"2023-07-19T11:26:34.960534Z"},"id":"g1gM2DvGeh2i","outputId":"e600a352-2cae-477a-8b94-cbc0ef6dcb44","trusted":true},"outputs":[],"source":["# Top-p (nucleus) text generation (10 samples):\n","sample_outputs = model.generate(generated, \n","                                do_sample=True,   \n","                                min_length=50, \n","                                max_length=MAXLEN,\n","                                top_k=10,                                 \n","                                top_p=0.9,        \n","                                temperature=0.9,\n","                                repetition_penalty=2.0,\n","                                num_return_sequences=10\n","                                )\n","\n","for i, sample_output in enumerate(sample_outputs):\n","    text = tokenizer.decode(sample_output, skip_special_tokens=True)\n","    a = len(title)  \n","    print(\"{}: {}\\n\\n\".format(i+1,  text[a:]))"]},{"cell_type":"markdown","metadata":{},"source":["## Applying Beam search technique\n","\n","Beam search is a search algorithm used in natural language processing (NLP) to generate the most likely sequence of words in a sentence, given a language model. It explores multiple possible word choices at each step and keeps a limited set (beam width) of the most promising options. This helps to find higher-quality sequences and improve the accuracy of text generation tasks like machine translation and text generation.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BAmwMuxa3xGW","outputId":"429ec8c0-4c8a-481a-e001-a944c734be49","trusted":true},"outputs":[],"source":["# Beam-search text generation:\n","sample_outputs = model.generate(generated, \n","                                do_sample=True,   \n","                                max_length=MAXLEN,                                                      \n","                                num_beams=5,\n","                                repetition_penalty=5.0,\n","                                early_stopping=True,      \n","                                num_return_sequences=1\n","                                )\n","\n","for i, sample_output in enumerate(sample_outputs):\n","    text = tokenizer.decode(sample_output, skip_special_tokens=True)\n","    a = len(title) \n","    print(\"{}: {}\\n\\n\".format(i+1,  text[a:]))"]},{"cell_type":"markdown","metadata":{"id":"B4UjMTwWx-ky"},"source":["### Comparison with raw GPT2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kbiaQldb1RPO","trusted":true},"outputs":[],"source":["tokenizer = get_tokenier()\n","model = get_model(tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H1ag9Z0iZbzG","outputId":"1aab1e57-e34c-4988-9575-994d790c03cc","trusted":true},"outputs":[],"source":["prompt = title\n","\n","generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n","device = torch.device(\"cuda\")\n","generated = generated.to(device)\n","\n","model.eval()\n","sample_outputs = model.generate(generated, \n","                                do_sample=True,   \n","                                max_length=MAXLEN,                                                      \n","                                num_beams=5,\n","                                repetition_penalty=5.0,\n","                                early_stopping=True,      \n","                                num_return_sequences=1\n","                                )\n","\n","for i, sample_output in enumerate(sample_outputs):\n","    print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
